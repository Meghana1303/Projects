
<h1> Problem Statement </h1>
<body>
  Online abuse, harassment and cyber-bullying remains a major concern for social media platforms such as twitter. With such plethora of users making offensive and targeted tweets on a daily basis, it has become of prime importance to filter out the tweets. Most targeted communities fall under the minority groups. Identifying abusive tweets manually is a challenging task since it requires immense man-power. 
In this paper we compare our results with Waseem et al. and build upon their methods to achieve better results.
 Our project investigates new preprocessing and State-of-the-art feature extraction techniques pertaining to twitter data. We compare our model's performance across various ML algorithms. 
</body>

<h2> Proposed Architecture </h2>
<img width="462" alt="image" src="https://user-images.githubusercontent.com/39126672/158036659-0fb46feb-2a6b-4317-a464-2b98e0bd4a48.png">


<h2> Discussions </h2>

<body>
  <ul>
    <li>We used combined techniques of undersampling and oversampling to achieve class imbalance.</li>
    <li> We applied twitter data specific pre-processing and normalization techniques </li>
    <li> We Created textual description for each emoticon and further
      created embedding for each emoticon </li>
    <li> We trained our model on ensemble learning techniques</li>
  </ul>
</body>


<h2> Conclusion </h2>
<body>
  Our experimentation with the embeddings generated by
BERTweet yields better results compaared to Waseem et al.BERTweet was trained
on twitter corpora. It has been trained on typical short length
tweets, informal grammar as well as irregular vocabulary such
as abbreviations, typographical errors and hashtags.
</body>
